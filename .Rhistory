# Reading in the Master files from TeamStreamz
# Date File Location
setwd("~/Documents/NUS_EBAC/Data") # data location of Mac
#setwd("C:/Users/theiv/Documents/2019_ISS_MTech_EBAC/Capstone Project/FYP_TeamsStreamz/wls20092020/Data") # location in Lenovo
#save.image("Base_DS_after_Filereads.RData")
load("Base_DS_after_Filereads.RData")
# ==> RM to 2009 RDATA
rm(pulsescore_Master_GB,pulsescore_Master_All)
# Coming back into current WD
setwd("~/wls26092020/wls26092020/")
# Sourcing the Underlying Functions
source("Code/underlyingfunctions.R")
# Sourcing and running the
source("Code/users_questions_marks_assessment_viewed.R")
## Installing all of the Libraries required :
library(tidyverse)
library(data.table)
library(dplyr)
library(reshape2)
library(recommenderlab)
library(devtools)
library(lubridate)
library(stringr)
s
# Coming back into current WD
setwd("~/wls26092020/wls26092020/")
# Sourcing and running the
source("Code/users_questions_marks_assessment_viewed.R")
#Recommendation Date
recDate = as.Date("2020-04-30")
## Assessments served to GB Org ID 28 alone
assess_dt_7_GB_org28 = unique(assess_dt_7 %>% filter (assess_dt_7$country == "GB") %>% filter(assess_dt_7_GB$org_id == "28"))
## Assessments served to GB
# Mutating Time fields for processing in assess_dt_7.
assess_dt_7$country = as.factor(assess_dt_7$country)
assess_dt_7$question_id = as.factor(assess_dt_7$question_id)
assess_dt_7$masked_user_id = as.factor(assess_dt_7$masked_user_id)
# convert timestamp into date time format
assess_dt_7$eventDateTime = as_datetime(assess_dt_7$submission_utc_ts,format="%Y-%m-%d %H:%M:%S.000")
# create new column  event date
assess_dt_7$eventDate = as.Date(substr(assess_dt_7$eventDateTime,1,10))
# create new column  event time
assess_dt_7$eventTime = substr(assess_dt_7$eventDateTime,12,22)
assess_dt_7_GB = unique(assess_dt_7 %>% filter (assess_dt_7$country == "GB"))
## Assessments served to GB Org ID 28 alone
assess_dt_7_GB_org28 = unique(assess_dt_7 %>% filter (assess_dt_7$country == "GB") %>% filter(assess_dt_7_GB$org_id == "28"))
#1) code : Test is May, Jun , Jul 2020
te_assess_dt_7_GB_org28 = assess_dt_7_GB_org28 %>% filter(eventDate > "2020-05-01")
#> count(te_assess_dt_7_GB_org28)
#n 1: 376
gb_te_users = data.frame(unique(te_assess_dt_7_GB_org28$masked_user_id))
#2) code : Training : April 2019 - April 2020  ==
tr_assess_dt_7_GB_org28 = assess_dt_7_GB_org28 %>% filter(eventDate > "2019-03-31", eventDate < "2020-05-01") #comma same as &
#> count(tr_assess_dt_7_GB_org28)
#n 1: 83206
gb_tr_users = data.frame(unique(tr_assess_dt_7_GB_org28$masked_user_id))
## checking if Test users are in the Training users set
names(gb_tr_users)[names(gb_tr_users) == "unique.tr_assess_dt_7_GB_org28.masked_user_id."] <- "masked_user_id"
names(gb_te_users)[names(gb_te_users) == "unique.te_assess_dt_7_GB_org28.masked_user_id."] <- "masked_user_id"
Test_USERS_GB = data.frame(gb_tr_users %>% filter (masked_user_id %in% gb_te_users$masked_user_id))
View(gb_te_users)
#removing the additional tables
rm(assess_dt_7_GB,gb_te_users,gb_tr_users)
## Preparation of Data to generate Pulse Score for GB train users
ASSES_PS_EVAL_GB_28 = tr_assess_dt_7_GB_org28[,-c("eventDate","eventTime","eventDateTime")]
## Calling the Pulse Score Code now..
FOR_PS = ASSES_PS_EVAL_GB_28
csvFileName <- paste("~/wls26092020/wls26092020/Data/pulsescore/pulse_score_",recDate,".csv")
## Calling the Pulse Score Code now..
FOR_PS = ASSES_PS_EVAL_GB_28
source("Code/PulseScore_Calculator.r")
# Running the Pulse Score and Pre Processor
#Recommendation Date
recDate = as.Date("2020-05-01")
source("Code/PS_Preprocessorr")
setwd("~/wls26092020/wls26092020")
source("Code/PS_Preprocessor.R")
# Running the Pulse Score and Pre Processor
#Recommendation Date
recDate = as.Date("2020-05-01")
source("Code/PS_Preprocessor.R")
rm(df,df_expanded_tag_set, df_ps_comp_set, df_question_diff_level, df_tag_fullset, df_tag_penalty_set,dt_cntry_full_data,dt_correct_ans, dt_dump,dt_final_user_ques_set)
rm(dt_tag_fullset,gb,kSet,penalty_map,tag_set,bands,c,cntDataSet,i,k,kValues,lvl,partitions,penalty_set,scaleValue,tag,x,y,z)
# Churning out the question and streams to be recommended
source("Code/upskill_users_streams_questions_Result.R")
# Churning out Recommendations
source("Code/Recommendations_Latest.R")
View(df_final_ps_score_set)
# Churning out Recommendations
source("Code/Recommendations_Latest.R")
# Churning out Recommendations
source("Code/Recommendations_Latest.R")
require(recommenderlab)
require(recommenderlab)
df_final_ps_score_set = df_final_ps_score_set %>% na.omit()
df_final_ps_score_set = df_final_ps_score_set %>% na.omit()
temp_all <- as(df_final_ps_score_set,"realRatingMatrix")
# Training Pulse Score, removing the test users ==> This ensures that the dimensions are all the same
# for the training and Prediction...
test_all  = temp_all[Test_USERS_GB,]
View(Test_USERS_GB)
# Demo Users FOR GUI
Demo_UsersDay0 = c("fe5e359d","abd51bd2","9bffe329","8f7b79fd","8100aef3","560d7304","4ffee38a","22408aad","108ae76d","035f412b")
df_final_ps_score_set = df_final_ps_score_set %>% na.omit()
temp_all <- as(df_final_ps_score_set,"realRatingMatrix")
# Training Pulse Score, removing the test users ==> This ensures that the dimensions are all the same
# for the training and Prediction...
test_all  = temp_all[Demo_UsersDay0,]
train_all = temp_all[] # %notin% c(Test_USERS_GB)
# Training Pulse Score, removing the test users ==> This ensures that the dimensions are all the same
# for the training and Prediction...
test_all  = temp_all[Test_USERS_GB,]
unlist(Test_USERS_GB)
as(Test_USERS_GB,"list")
Test_USERS_GB = as(Test_USERS_GB,"list")
View(Test_USERS_GB)
Test_USERS_GB = data.frame(gb_tr_users %>% filter (masked_user_id %in% gb_te_users$masked_user_id))
# Churning out Recommendations
source("Code/Recommendations_Latest.R")
View(Recommended_Tags)
# Churning out the question and streams to be recommended
source("Code/upskill_users_streams_questions_Result.R")
## After Recommendation, need to pull out the Questions now:
Questions_Recommended = merge(C_Q_Tag_M, Recommended_Tags, by= c("question_tags"),allow.cartesian=TRUE)
## Merging with u_q_t_m to find out which of the questions recommended have already been answered by users
Questions_Recommended$masked_user_id <- as.factor(Questions_Recommended$masked_user_id)
Questions_Recommended$question_id <- as.factor(Questions_Recommended$question_id)
Questions_Recommended_w_qns_ans = unique(merge(Questions_Recommended,u_q_t_M,  by= c("masked_user_id","question_id"),all.x = TRUE))
u_q_t_M$question_id <- as.factor(u_q_t_M$question_id)
Questions_Recommended_w_qns_ans = unique(merge(Questions_Recommended,u_q_t_M,  by= c("masked_user_id","question_id"),all.x = TRUE))
Questions_Recommended_w_qns_ans[,c("no_of_trials","points_earned")] <- NULL
Questions_Recommended_w_qns_ans = unique(Questions_Recommended_w_qns_ans)
# Churning out the question and streams to be recommended
source("Code/upskill_users_streams_questions_Result.R")
View(Stream_Reco_Day_50S)
# Churning out the question and streams to be recommended
source("Code/upskill_users_streams_questions_Result.R")
View(Qns_Reco_Day_50Q)
View(ASSES_PS_EVAL_GB_28)
# Churning out the question and streams to be recommended
source("Code/upskill_users_streams_questions_Result.R")
View(Qns_Reco_Day_50Q)
View(Stream_Reco_Day_50S)
